---
title: "UAV_Shrub_SliceDice"
author: "Georgia Harrison"
date: "10/25/2022"
output: html_document
---

################################################
# notes

clipping lidar data with polygon https://github.com/r-lidar/lidR/issues/134

################################################


## Workflow
1. Import files: dense point cloud, shrub field data, and
2. Create shapefiles for each shrub corners
3. Extract each shrub within shapefile boundaries from dense pt cloud



# 1. Import files: dense point cloud, shrub field data, and
## library packages 
```{r}
library(tidyverse)
library(lidR)
library(rgdal)
library(raster)
```

# 1. Import and describe files
currently just importing from my desktop but we could be fancy and do through git directly

Set working directory for REM 475 Group project onedrive

### Dense point cloud
exorted from agisoft using high quality and mild point filtering
```{r}

```

### Field data
Shrub ID, field size measurements, and corner numbers
```{r}
shrub_field <- read.csv("C:/Users/harr4718/OneDrive - University of Idaho/Courses/REM 475 Drones/REM 475 Group Project/shrub_field_data.csv", 
                        header=TRUE,  stringsAsFactors = FALSE)
head(shrub_field)
```

## corners
RTK GPS points for the 4 corners surrounding each shrub
*note that this is the updated file with PPK adjustment*
```{r}
# corner <- read.csv("/Input data - Imagery and GCPs/Shrub_corners/shrub_kill_corner_markers_corrected.csv", header=TRUE,
#                    stringsAsFactors = FALSE)

corner <- read.csv("C:/Users/harr4718/OneDrive - University of Idaho/Courses/REM 475 Drones/REM 475 Group Project/Input data - Imagery and GCPs/Shrub_corners/shrub_kill_corner_markers_corrected.csv", header=TRUE, 
                                                stringsAsFactors = FALSE)
```

Make sure that ellipsoid height, lat and long are all numeric data types 

```{r}
corner$Longitude <- as.numeric(corner$Longitude)
corner$Latitude <- as.numeric(corner$Latitude)
corner$Ellipsoidal.height <- as.numeric(corner$Ellipsoidal.height)
```




## start off with something straightforward
Get average Z value for each shrub - I think you can do this without creating a spatial data frame

convert shrub field data from wide to long format - corner numbers
```{r}
head(shrub_field)
shrub_long = shrub_field %>%
  pivot_longer(cols = c('corner1', 'corner2', 'corner3', 'corner4'),
               values_to = 'Name')
head(shrub_long)
```

merge corner and long format field data 
```{r}
#we will be joining by the Name column ( # of corner), but make same data type 
shrub_long$Name = as.character(shrub_long$Name)
corner$Name = as.character(corner$Name)

shrub_corner_merge = 
  full_join(shrub_long, corner, by="Name")
```



Remove rows with NA
```{r}
shrub_corner_merge_noNA = shrub_corner_merge %>% drop_na(species_name)
```


get average Z value for each shrub 
```{r}
#Z is Ellipsoidal.height

#make data it numeric form
typeof(shrub_corner_merge_noNA$Ellipsoidal.height)
shrub_corner_merge_noNA$Ellipsoidal.height <-as.numeric(shrub_corner_merge_noNA$Ellipsoidal.height)


ground_elev = 
  shrub_corner_merge_noNA %>% 
  group_by(Shrub_ID) %>%
  summarize(mean_z = mean(Ellipsoidal.height),
            sd_z = sd(Ellipsoidal.height))
```

add the mean z on the original field data 
```{r}
shrub_field = 
  left_join(shrub_field, ground_elev, by="Shrub_ID")

```



# 2. Create shapefiles for each shrub corners
Start out by doing this with 1 shrub! 

select one shrub (using unique shrub ID) from merged file of field data + corner points
```{r}
head(shrub_corner_merge_noNA)
unique_shrubIDs = (shrub_corner_merge_noNA$Shrub_ID) #list of the all the shrubs by their ID 
#there is a weird NA?? those are points which are not assigned to a specific shrub. Deal with this later 


#try to subsample within larger files to one which only meet condition of each ID
#make this work for one shrub first before we loop it
one_shrub_corner = shrub_corner_merge_noNA%>% filter(Shrub_ID=="ARTRW_1")

one_shrub_corner


#try to make this a loop
#for (name in unique_shrubIDs){
#  one_shrub_corner = shrub_corner_merge_noNA%>% filter(Shrub_ID==name)
#}
  

```


create shapefile from indivudal shrub corners

```{r}
#convert corners for EACH shrub to a spatial data frame (shapefile)

#start out with our one shrub example
one_shrub_corner

#identify column numbers for lat and long
which(colnames(one_shrub_corner)=="Longitude") #25
which(colnames(one_shrub_corner)=="Latitude") #26

#describe the CRS
utm11nCRS<- crs("+proj=utm +zone=11N +datum=WGS84 +units=m +no_defs 
				 +ellps=WGS84 +towgs84=0,0,0" )

#create spatial data frame
one_shrub_sdf <- SpatialPointsDataFrame(one_shrub_corner[,25:27],
                    one_shrub_corner,    #the R object to convert
                    proj4string = utm11nCRS)   # assign a CRS 
                                          
# plot spatial object
plot(one_shrub_sdf, 
     main="Map of one shrub corners")

```



# some issue with NA values in the original dataset, tried cleaning and have not gotten anything to work
Should look into if there is a better way to store the outputs, like a custom environment
```{r}

tail(shrub_corner_merge_noNA)

#get list of all uniuque shrub IDs
unique_shrubIDs = unique(shrub_corner_merge_noNA$Shrub_ID)
#create CRS
utm11nCRS<- crs("+proj=utm +zone=11N +datum=WGS84 +units=m +no_defs 
				 +ellps=WGS84 +towgs84=0,0,0" )

#try to make this a loop

for (name in unique_shrubIDs){
  print(name)
  temp_dirty = shrub_corner_merge_noNA[shrub_corner_merge_noNA$Shrub_ID == name,]
  temp_clean = temp_dirty[!is.na(temp_dirty$species_name),]

  #create spatial data frame
  temp_dsf <- SpatialPointsDataFrame(temp_clean[,25:27],
                      temp_clean,    #the R object to convert
                      proj4string = utm11nCRS)   # assign a CRS 
  assign(x=paste0(name, "_sdf"), 
         value = temp_dsf, 
         envir = shrub_sdfs)
}

```
So this is working for now, but it spits out all the SDFs in the global environment within R. Not ideal but maybe okay for now?


get list of all the shrub sdf for later loopin
```{r}
shrub_sdfs<-grep("_sdf",names(.GlobalEnv),value=TRUE)
print(shrub_sdfs)

list2 <- mget(ls(), .GlobalEnv)
list2
```






# Segmenting .las point cloud to shapefile (.shp) (or SpatialPolygon (sp))
### NOTE: the polygon that defines the 4 corners and outlines the shrub does not have to be in a shapefile (.shp) format, the 'clip_roi' function that is used to segment (clip) the point cloud to the polygon only takes in the vector as a SpatialPolygon (sp) so no matter what format the vector is in, the script will convert it to sp class 

## Loading data and converting to required data class format:

### Load necessary libraries 
```{r}
require(sp)
#require(sf)
require(raster)
require(rLiDAR)
require(lidR)
require(rgdal)
require(terra)
library(sf)
library(stars)


```

### Import point cloud as LAS catalog. I think it is better to use a 'LAS catalog' format as it is easier to clip multifeature polygon (vector file containing a lot of polygons). 

```{r}
#las <- readLAScatalog("~/[FilePath]/[PointCloud_FileName].las")

las <- readLAScatalog("C:/Users/harr4718/OneDrive - University of Idaho/Courses/REM 475 Drones/REM 475 Group Project/Intermediate outputs - Metashape, Arc, R etc/PointCloud.las")


las <- readLAS("C:/Users/harr4718/OneDrive - University of Idaho/Courses/REM 475 Drones/REM 475 Group Project/Intermediate outputs - Metashape, Arc, R etc/PointCloud.las")


```

### Set CRS for LAScatalog (Point Cloud data)
```{r}
st_crs(las) <- 6340 #set to NAD83 Z11 (same as Shapefile or other Vector format used)

```





### Importing shapefile for clipping the point cloud as a 'simple feature' (sf) class. IGNORE if the vector file to be used for segmentation is alread in 'SpatialPolygon' (sp) class, SKIP to line [ ]
``` {r}
sf <- st_read(dsn = "~/[FilePath]/[Shapefile_FileName].shp", layer = "[Shapefile_FileName]")

```

### The imported 'simple feature (sf)' class (shapefile) has XYZ dimension, the 'clip_roi' function to be used to segment the point cloud can only take in SpatialPolygon data that is in XY dimensions.
### Remove Z dimension of the sf class data (imported shapefile)
```{r}
sf_rmZ <- st_zm(sf) #'sf_zm' function removes the Z dimension to create an sf class with only XY dimensions 

```
### Convert the 2 dimension sf class to sp class (simple feature to spatial polygon)
```{r}
SpP <- as(st_geometry(sf_rmZ), "Spatial")

```



## Clipping vector data (sp class) to point cloud data (LAS catalog class)

### Set desitnation file path and file naming rule for the individual point clouds outputs (for each polygon). 
### NOTES: 
### -  The file naming rule should be based on an ID feature that defines each polygon of the vector dataset ('SpP' dataset).The ID feature should be set while creating the shapefile or whatever the vector file we create for the 4 corners. 
### - It is basically something that defines each polygon we create and thus defines each plant, can be as simple as a column called 'ObjectID' or 'ID' and numbering from 1 to however many polygons we have in total (I think we have around 100?) s

```{r}
opt_output_files(las) <- "~/[FilePath]/[Segmented_PointCloud_Name]_{ID}" #this sets up the directory where the R will save the segmented point clouds.

#For example if '[Segmented_PointCloud_Name]_{ID}' is set as 'Shrub_{ID}' and {ID} is the name of the feature in the vector file used that uniquely defines each polygon (e.g. ID = 01), then the output point cloud will be named as 'shrub_01.las'

```

### Segmenting the point cloud (.las file) to the 4-corner vector files (sp format)

```{r}
clipped_las <- clip_roi(las,SpP) 

#'clip_roi' is the new function that replaced 'lasclip'. If you try to use 'lasclip' function, it will return a message that the fucntion is now defunct and suggests you to use 'clip_roi' function. 
```
