---
title: "UAV_Shrub_SliceDice"
author: "Georgia Harrison"
date: "10/25/2022"
output: html_document
---

################################################
# notes

clipping lidar data with polygon https://github.com/r-lidar/lidR/issues/134

################################################


## Workflow
1. Import files: dense point cloud, shrub field data, and
2. Create shapefiles for each shrub corners
3. Extract each shrub within shapefile boundaries from dense pt cloud



# 1. Import files: dense point cloud, shrub field data, and
## library packages 
```{r}
library(tidyverse)
library(lidR)
library(rgdal)
library(raster)
```

# 1. Import and describe files
currently just importing from my desktop but we could be fancy and do through git directly

Set working directory for REM 475 Group project onedrive

### Dense point cloud
exported from agisoft using high quality and mild point filtering
```{r}

```

### Field data
Shrub ID, field size measurements, and corner numbers
```{r}
shrub_field <- read.csv("C:\\Users\\shre9292\\OneDrive - University of Idaho\\Documents\\GitHub\\UAVShrubVolume\\DATA\\shrub_field_data.csv", 
                        header=TRUE,  stringsAsFactors = FALSE)
head(shrub_field)
```

## corners
RTK GPS points for the 4 corners surrounding each shrub
*note that this is the updated file with PPK adjustment*
```{r}
# corner <- read.csv("/Input data - Imagery and GCPs/Shrub_corners/shrub_kill_corner_markers_corrected.csv", header=TRUE,
#                    stringsAsFactors = FALSE)

corner <- read.csv("C:\\Users\\shre9292\\OneDrive - University of Idaho\\Documents\\GitHub\\UAVShrubVolume\\DATA\\shrub_kill_corner_markers_corrected.csv", header=TRUE, 
                                                stringsAsFactors = FALSE)
```

Make sure that ellipsoid height, lat and long are all numeric data types 

```{r}
corner$Longitude <- as.numeric(corner$Longitude)
corner$Latitude <- as.numeric(corner$Latitude)
corner$Ellipsoidal.height <- as.numeric(corner$Ellipsoidal.height)
```




## start off with something straightforward
Get average Z value for each shrub - I think you can do this without creating a spatial data frame

convert shrub field data from wide to long format - corner numbers
```{r}
head(shrub_field)
shrub_long = shrub_field %>%
  pivot_longer(cols = c('corner1', 'corner2', 'corner3', 'corner4'),
               values_to = 'Name')
head(shrub_long)
```

merge corner and long format field data 
```{r}
#we will be joining by the Name column ( # of corner), but make same data type 
shrub_long$Name = as.character(shrub_long$Name)
corner$Name = as.character(corner$Name)

shrub_corner_merge = 
  full_join(shrub_long, corner, by="Name")
```



Remove rows with NA
```{r}
shrub_corner_merge_noNA = shrub_corner_merge %>% drop_na(species_name)
```


get average Z value for each shrub 
```{r}
#Z is Ellipsoidal.height

#make data it numeric form
typeof(shrub_corner_merge_noNA$Ellipsoidal.height)
shrub_corner_merge_noNA$Ellipsoidal.height <-as.numeric(shrub_corner_merge_noNA$Ellipsoidal.height)


ground_elev = 
  shrub_corner_merge_noNA %>% 
  group_by(Shrub_ID) %>%
  summarize(mean_z = mean(Ellipsoidal.height),
            sd_z = sd(Ellipsoidal.height))
```

add the mean z on the original field data 
```{r}
shrub_field = 
  left_join(shrub_field, ground_elev, by="Shrub_ID")

```



# 2. Create shapefiles for each shrub corners
Start out by doing this with 1 shrub! 

select one shrub (using unique shrub ID) from merged file of field data + corner points
```{r}
head(shrub_corner_merge_noNA)
unique_shrubIDs = (shrub_corner_merge_noNA$Shrub_ID) #list of the all the shrubs by their ID 
#there is a weird NA?? those are points which are not assigned to a specific shrub. Deal with this later 


#try to subsample within larger files to one which only meet condition of each ID
#make this work for one shrub first before we loop it
one_shrub_corner = shrub_corner_merge_noNA%>% filter(Shrub_ID=="ARTRW_1")

one_shrub_corner


#try to make this a loop
#for (name in unique_shrubIDs){
#  one_shrub_corner = shrub_corner_merge_noNA%>% filter(Shrub_ID==name)
#}
  

```


create shapefile from indivudal shrub corners

```{r}
#convert corners for EACH shrub to a spatial data frame (shapefile)

#start out with our one shrub example
one_shrub_corner

#identify column numbers for lat and long
which(colnames(one_shrub_corner)=="Longitude") #25
which(colnames(one_shrub_corner)=="Latitude") #26

#describe the CRS
utm11nCRS<- crs("+proj=utm +zone=11N +datum=WGS84 +units=m +no_defs 
				 +ellps=WGS84 +towgs84=0,0,0" )

#create spatial data frame
one_shrub_sdf <- SpatialPointsDataFrame(one_shrub_corner[,25:27],
                    one_shrub_corner,    #the R object to convert
                    proj4string = utm11nCRS)   # assign a CRS 
                                          
# plot spatial object
plot(one_shrub_sdf, 
     main="Map of one shrub corners")

```



# some issue with NA values in the original dataset, tried cleaning and have not gotten anything to work
Should look into if there is a better way to store the outputs, like a custom environment
```{r}

trial = shrub_corner_merge_noNA%>% filter(!Shrub_ID=="ARTRW_1")







trial = shrub_corner_merge_noNA%>% filter(!Shrub_ID=="ARTRW_1")




#get list of all uniuque shrub IDs
unique_shrubIDs = unique(trial$Shrub_ID)
#create CRS
utm11nCRS<- crs("+proj=utm +zone=11N +datum=WGS84 +units=m +no_defs
                 +ellps=WGS84 +towgs84=0,0,0" )



#try to make this a loop



for (name in unique_shrubIDs){
  print(name)
  temp_dirty = trial[trial$Shrub_ID == name,]
  temp_clean = temp_dirty[!is.na(temp_dirty$species_name),]



 #create spatial data frame
  temp_dsf <- SpatialPointsDataFrame(temp_clean[,25:27],
                      temp_clean,    #the R object to convert
                      proj4string = utm11nCRS)   # assign a CRS
  assign(x=paste0(name, "_sdf"),
         value = temp_dsf,
         envir = .GlobalEnv)
}
```
So this is working for now, but it spits out all the SDFs in the global environment within R. Not ideal but maybe okay for now?


get list of all the shrub sdf for later loopin
```{r}
shrub_sdfs<-grep("_sdf",names(.GlobalEnv),value=TRUE)
print(shrub_sdfs)

list2 <- mget(ls(), .GlobalEnv)
list2

```

#------------------------------------------------------------------------------------------------------------------------------------------------------------
#Clipping point cloud to shapefile

##Loading required packages
```{r}
require(sp)
require(sf)
require(raster)
require(rLiDAR)
require(lidR)
require(rgdal)
require(terra)

```

##Importing point cloud as LAS catalog 
```{r}

las <- readLAScatalog("~/[FilePath]/[FileName].las")

las$CRS #to check the CRS of the imported las. Returns 6340 -> EPSG code for NAD83(2011) / UTM zone 11N 

```

Notes regarding use of LAS Catalog format: 
- Efficient memory management, especially for large .las files
- Enables clipping of multifeature polygons (e.g. a shapefile containing multiple polygon features)

##Importing shapefile as simple feature (sf) class
```{r}
sf <- st_read(dsn = "C:\\Users\\shre9292\\OneDrive - University of Idaho\\Documents\\GitHub\\UAVShrubVolume\\DATA\\shrubs_arc.shp", layer = "shrubs_arc") 

sf #returns Dimensions as 'XY' and Projected CRS as NAD83(2011) / UTM zone 11N (same as point cloud on line 252), if sf has Dimensions XYZ, refer to NOT RUN section starting from line 288.

```

Notes regarding importing the shapfile for the case of REM 475 project: 
  - I imported the shapefile I created in ArcGIS where:
    - I imported the final output shapefile from Georgia's script (in EPSG 4152, geographic) into ArcGIS
    - Used the 'export' feature to export the EPSG 4152 geographic shapefile to EPSG 6340 projected shapefile

##Setting destination of the output clipped point cloud files (.las)
```{r}
opt_output_files(las) <- "~/[FilePath]/[FileName]_{ID}"

```

For e.g.: If '[FileName]_{ID}' is set as 'shrub_{Shrub_ID}', then the output file will be named as 'shrub_ARAR_1.las' where 'ARAR_1' is the unique ID ('{Shrub_ID}') of polygon feature of the shapefile, and hence is the ID of the individual shrub IRL.

##Clipping shapefile to point cloud 
```{r}
clipped_las <- clip_roi(las,sf)

```
There is no need to export the 'clipped_las' variable, the 'opt_output_files(las)' function automatically exports the files in the folder defined in line 275

#------------------------------------------------------------------------------------------------------------------------------------------------------------
## NOT RUN: this section of the script can be used if the imported shapefile has XYZ dimension. This portion of the script removes the Z dimension and converts the sf to Spatial polygons class (SpP)
IF NEED TO RUN:

```{r}

#sf class has XYZ dimension, need to convert to 2 dimension (XY) 'SpatialPolygon' class:

sf_rmZ <- st_zm(sf) #removes Z dimension
SpP <- as(st_geometry(sf), "Spatial") #converts sf to sp class

```